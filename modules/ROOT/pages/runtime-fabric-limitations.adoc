= Limitations (Anypoint Runtime Fabric on VMs / Bare Metal)
ifndef::env-site,env-github[]
include::_attributes.adoc[]
endif::[]

The following information is important when installing, configuring, and managing Anypoint Runtime Fabric on VMs / Bare Metal.


== Node, Environment, and Group Limitations

The following limits are based on internal performance testing and are lower than those provided by supported Kubernetes providers. If you need to scale beyond the following limits, ensure that you first run tests in lower environments to validate the performance of your clusters.

[%header%autowidth.spread]
|===
| Nodes | The maximum number of nodes is 30.
| Node types | VM-based nodes are required. For example, Fargate is not supported.
| Replicas per application | The maximum number of replicas per application is 8.
| Replicas per node | The maximum number of replicas that can be deployed per node is 40.

To allow core sharing across replicas when needed for bursting, run no more than 20-25 *replicas per core*. This ensures the Runtime Fabricâ€™s internal components that run on each worker node are not overloaded by too many replicas.
| Associated environments per Runtime Fabric | You can associate a Runtime Fabric with up to 100 environments in any Business Group. For example, if you associate a development and a production environment with Org A and a dev environment with Org B, that is three environment associations. 
| Business groups | You can create up to 50 Runtime Fabrics per org in a Business Group. Any sub org can contain up to 50 Runtime Fabrics, in addition to any shared by another sub org. For example, if you have master Org A and its child Org B, you can have 50 Runtime Fabrics in Org A and 50 in Org B. You can also share all 50 Runtime Fabrics from Org A with Org B, and as a result, you will see 100 Runtime Fabrics in total in the list view of Org B.
| Object store persistence | To manage data persistence across Mule application replicas and restarts, Anypoint Runtime Fabric uses Persistence Gateway. See xref:persistence-gateway.adoc[Persistence Gateway].
|===

== Internal Load Balancer Resource Allocation and Performance

The following table lists the approximate number of requests (averaging 10 KB) that can be served with a single replica of the internal load balancer based on the number of CPU cores. This information is based on the performance test results as described in xref:deploy-resource-allocation#internal-load-balancer[Resource Allocation and Performance on Anypoint Runtime Fabric on VMs / Bare Metal].

[%header,cols="3*a"]
|===
| vCPU Cores | Max Requests per Second (Connection Reuse) | Max Requests per Second (No Connection Reuse)
| `1.00` | 2000 | 175
| `0.75` | 1500 | 100
| `0.50` | 1000 | 50
| `0.25` | 100 | 10
|===

The internal load balancer runs on the controller nodes of Runtime Fabric on VMs / Bare Metal. Configure the VM size based on the amount and
type of inbound traffic. You can allocate only half of the available CPU cores on each VM to the internal load balancer.
Refer to xref:deploy-resource-allocation#internal-load-balancer[Resource Allocation and Performance on Anypoint Runtime Fabric] for additional information.

== Operating System Limitations

The following table lists known limitations for host operating systems in Runtime Fabric:
[%header%autowidth.spread]
|===
| Operating System | Limitation
| RHEL 8 a| 
* Do not set the optional environment variable `disable_selinux` to `false` in the `fabric.tf` script, or installation will fail.
* Do not set SELinux to enforcing mode. 
| RHEL 7 a| 
* If you have enabled SELinux, third-party software running on the host may change policy settings from SELinux.
* You can set SELinux to enforcing mode if you don't change default policies.
| RHEL | Runtime Fabric only supports instances of RHEL with Logical Volume Manager (LVM) on Azure Bare Metal. Non-LVM instances of RHEL on Azure Bare Metal are not supported. 
|===

[[how-antivirus-and-dpi-software-impacts-runtime-fabric-functionality]]

include::partial$antivirus-statement.adoc[]
